# ğŸ§  VibeCheck.AI

> Real-time emotion detection from your **face** and **voice** â€” fused into one final vibe ğŸ­

VibeCheck.AI is a fun and powerful multimodal AI tool that uses your **webcam** and **microphone** to detect how you're feeling â€” based on **facial expressions** and **tone of voice**. It shows everything in a live OpenCV window with instant updates.

---

<!-- ## ğŸ¬ Demo

![Demo GIF](assets/demo.gif)  
*(Optional â€” add a screen recording or screenshot here)*

--- -->

## ğŸ’¡ Features

- ğŸ§  **Facial Emotion Detection** using DeepFace
- ğŸ¤ **Voice Emotion Detection** from MFCC features (librosa)
- ğŸ”€ **Fusion Logic** to combine both inputs into a final "vibe"
- ğŸª Live webcam feed with overlaid emotions
- ğŸ’» Cross-platform and real-time (no browser, no freezing!)

---

## ğŸ› ï¸ Tech Stack

- `Python 3.10`
- `OpenCV` â€” webcam + display
- `DeepFace` â€” facial emotion recognition
- `librosa` + `sounddevice` â€” real-time voice capture + analysis
- `NumPy`, `threading` â€” smooth and async logic

---

## ğŸš€ Getting Started


```bash
1. Clone this repo

git clone https://github.com/YOUR_USERNAME/VibeCheck.AI.git
cd VibeCheck.AI

2. Create a virtual environment (optional)

python3 -m venv .venv
source .venv/bin/activate

3. Install dependencies

pip install -r requirements.txt

4. Run the app

python3 vibecheck_cv.py
Press Q to quit

